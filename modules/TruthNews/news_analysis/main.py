#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ™ºèƒ½æ–°é—»åˆ†æç³»ç»Ÿ - ä¸»ç¨‹åº
è‡ªåŠ¨åŒ–ä¸ƒæ­¥æµç¨‹ï¼šä»æ–°é—»è·å–åˆ°æ·±åº¦åˆ†æçš„å®Œæ•´é“¾è·¯
"""

import sys
import os
import json
import traceback
from datetime import datetime
from dotenv import load_dotenv

# å¯¼å…¥å„ä¸ªæ­¥éª¤çš„æ¨¡å—
from src.step1_fetch_news import step1_fetch_and_clean_news
from src.step2_filter_accessible import run_step2
from src.step3_ai_relevance_filter import step3_ai_relevance_filter
from src.step4_fetch_html import step4_fetch_html_pages
from src.step5_extract_content import step5_extract_article_content
from src.step6_ai_analysis import step6_ai_analysis
from src.step7_final_summary import step7_generate_final_summary

def print_banner():
    """æ‰“å°ç¨‹åºæ¨ªå¹…"""
    banner = """
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    æ™ºèƒ½æ–°é—»åˆ†æç³»ç»Ÿ                          â•‘
â•‘                 Intelligent News Analysis System             â•‘
â•‘                                                              â•‘
â•‘  è‡ªåŠ¨åŒ–ä¸ƒæ­¥æµç¨‹ï¼šæ–°é—»è·å– â†’ ç­›é€‰ â†’ åˆ†æ â†’ æ±‡æ€»æŠ¥å‘Š          â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""
    print(banner)

def print_step_separator():
    """æ‰“å°æ­¥éª¤åˆ†éš”ç¬¦"""
    print("\n" + "="*60 + "\n")

def validate_environment():
    """éªŒè¯ç¯å¢ƒå˜é‡é…ç½®"""
    print("æ­£åœ¨éªŒè¯ç¯å¢ƒé…ç½®...")
    
    required_vars = [
        'GLM_API_KEY',
        'GEMINI_API_KEY'
    ]
    
    missing_vars = []
    for var in required_vars:
        if not os.getenv(var):
            missing_vars.append(var)
    
    if missing_vars:
        print(f"âŒ ç¼ºå°‘å¿…è¦çš„ç¯å¢ƒå˜é‡: {', '.join(missing_vars)}")
        print("è¯·æ£€æŸ¥ .env æ–‡ä»¶æˆ–è®¾ç½®ç›¸åº”çš„ç¯å¢ƒå˜é‡")
        return False
    
    print("âœ… ç¯å¢ƒé…ç½®éªŒè¯é€šè¿‡")
    return True

def display_final_results(query, final_report_file):
    """æ˜¾ç¤ºæœ€ç»ˆç»“æœ"""
    print_step_separator()
    print("ğŸ‰ æ™ºèƒ½æ–°é—»åˆ†æå®Œæˆï¼")
    print_step_separator()
    
    try:
        with open(final_report_file, 'r', encoding='utf-8') as f:
            final_report = json.load(f)
        
        print(f"ğŸ“Š åˆ†æä¸»é¢˜: {query}")
        print(f"ğŸ“… å®Œæˆæ—¶é—´: {final_report['generated_time']}")
        print(f"ğŸ“ˆ å·¥ä½œæµç»Ÿè®¡:")

        if 'workflow_summary' in final_report:
            workflow = final_report['workflow_summary']
            print(f"   â€¢ åŸå§‹æ–°é—»è·å–: {workflow['step1_raw_news']} æ¡")
            print(f"   â€¢ è¿é€šæ€§ç­›é€‰: {workflow['step2_accessible']} æ¡")
            print(f"   â€¢ ç›¸å…³æ€§ç­›é€‰: {workflow['step3_relevant']} æ¡")
            print(f"   â€¢ å†…å®¹æå–æˆåŠŸ: {workflow['step5_content_extracted']} æ¡")
            print(f"   â€¢ AIåˆ†ææˆåŠŸ: {workflow['step6_analyzed']} æ¡")
        else:
            print(f"   â€¢ æ€»æ–°é—»æ•°: {final_report.get('total_news_analyzed', 0)} æ¡")
            print(f"   â€¢ åˆ†æç±»å‹: {final_report.get('analysis_type', 'unknown')}")
        
        print(f"\nğŸ“ æœ€ç»ˆæ±‡æ€»æŠ¥å‘Š:")
        print("-" * 50)
        print(final_report['final_summary'])
        print("-" * 50)
        
        print(f"\nğŸ’¾ å®Œæ•´æŠ¥å‘Šå·²ä¿å­˜åˆ°: {final_report_file}")
        
    except Exception as e:
        print(f"âŒ è¯»å–æœ€ç»ˆæŠ¥å‘Šæ—¶å‡ºé”™: {e}")

def run_news_analysis_pipeline(query):
    """
    è¿è¡Œå®Œæ•´çš„æ–°é—»åˆ†ææµç¨‹
    
    Args:
        query (str): æœç´¢å…³é”®è¯
    
    Returns:
        str: æœ€ç»ˆæŠ¥å‘Šæ–‡ä»¶è·¯å¾„
    """
    start_time = datetime.now()
    
    try:
        # æ­¥éª¤1: è·å–æ–°é—»åˆ—è¡¨ä¸é¢„æ¸…ç†
        print_step_separator()
        step1_result = step1_fetch_and_clean_news(query)
        
        # æ­¥éª¤2: è¿é€šæ€§ç­›é€‰
        print_step_separator()
        step2_result = run_step2(query)
        
        # æ­¥éª¤3: AIç›¸å…³æ€§ç­›é€‰
        print_step_separator()
        step3_result = step3_ai_relevance_filter(query)
        
        # æ­¥éª¤4: è·å–åŸå§‹HTML
        print_step_separator()
        step4_result = step4_fetch_html_pages(query)
        
        # æ­¥éª¤5: æå–æ­£æ–‡
        print_step_separator()
        step5_result = step5_extract_article_content(query)
        
        # æ­¥éª¤6: AIæ·±åº¦åˆ†æ
        print_step_separator()
        step6_result = step6_ai_analysis(query)
        
        # æ­¥éª¤7: ç”Ÿæˆæœ€ç»ˆæ±‡æ€»æŠ¥å‘Š
        print_step_separator()
        step7_result = step7_generate_final_summary(query)
        
        end_time = datetime.now()
        duration = end_time - start_time
        
        print_step_separator()
        print(f"âœ… æ‰€æœ‰æ­¥éª¤æ‰§è¡Œå®Œæˆï¼")
        print(f"â±ï¸  æ€»è€—æ—¶: {duration}")
        
        return step7_result
        
    except Exception as e:
        print(f"\nâŒ æ‰§è¡Œè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        print(f"ğŸ“ é”™è¯¯è¯¦æƒ…:")
        traceback.print_exc()
        raise

def main():
    """ä¸»å‡½æ•°"""
    print_banner()
    
    # åŠ è½½ç¯å¢ƒå˜é‡
    load_dotenv()
    
    # éªŒè¯ç¯å¢ƒé…ç½®
    if not validate_environment():
        sys.exit(1)
    
    # è·å–ç”¨æˆ·è¾“å…¥
    if len(sys.argv) > 1:
        query = sys.argv[1]
    else:
        query = input("\nè¯·è¾“å…¥æœç´¢å…³é”®è¯: ").strip()
    
    if not query:
        print("âŒ æœç´¢å…³é”®è¯ä¸èƒ½ä¸ºç©º")
        sys.exit(1)
    
    print(f"\nğŸ” å¼€å§‹åˆ†æä¸»é¢˜: '{query}'")
    print(f"ğŸ• å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    try:
        # è¿è¡Œå®Œæ•´çš„åˆ†ææµç¨‹
        final_report_file = run_news_analysis_pipeline(query)
        
        # æ˜¾ç¤ºæœ€ç»ˆç»“æœ
        display_final_results(query, final_report_file)
        
    except KeyboardInterrupt:
        print("\n\nâš ï¸  ç”¨æˆ·ä¸­æ–­äº†ç¨‹åºæ‰§è¡Œ")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()
