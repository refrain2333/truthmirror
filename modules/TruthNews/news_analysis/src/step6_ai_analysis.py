#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ­¥éª¤6: AIæ·±åº¦åˆ†æž
ä½¿ç”¨Gemini-2.0-flash-expæ¨¡åž‹å¯¹æ¯ç¯‡æ–°é—»è¿›è¡Œæ·±åº¦åˆ†æž
"""

import requests
import json
import os
import glob
import time
from datetime import datetime
from dotenv import load_dotenv

# åŠ è½½çŽ¯å¢ƒå˜é‡
load_dotenv()

def call_glm_analysis_api(content, prompt_template):
    """
    è°ƒç”¨GLM APIè¿›è¡Œæ–°é—»åˆ†æž

    Args:
        content (str): æ–°é—»æ­£æ–‡å†…å®¹
        prompt_template (str): æç¤ºè¯æ¨¡æ¿

    Returns:
        tuple: (success, analysis_result, error_message)
    """
    api_url = os.getenv('GLM_API_URL', 'https://open.bigmodel.cn/api/paas/v4/chat/completions')
    api_key = os.getenv('GLM_API_KEY')
    model_id = os.getenv('GLM_MODEL_ID', 'glm-4.5-flash')

    if not api_key:
        raise ValueError("GLM_API_KEYçŽ¯å¢ƒå˜é‡æœªè®¾ç½®")

    # ä»ŽçŽ¯å¢ƒå˜é‡èŽ·å–åˆ†æžæç¤ºè¯
    analysis_prompt_template = os.getenv('GLM_ANALYSIS_PROMPT', prompt_template)
    # æž„å»ºå®Œæ•´çš„æç¤ºè¯
    full_prompt = analysis_prompt_template.format(content=content)

    headers = {
        'Authorization': f'Bearer {api_key}',
        'Content-Type': 'application/json'
    }

    data = {
        "model": model_id,
        "messages": [
            {
                "role": "user",
                "content": full_prompt
            }
        ],
        "temperature": 0.7,
        "max_tokens": 1024
    }

    try:
        # ç¡®ä¿URLæ­£ç¡®
        full_url = f"{api_url.rstrip('/')}/chat/completions"
        response = requests.post(
            full_url,
            headers=headers,
            json=data,
            timeout=60
        )
        response.raise_for_status()

        result = response.json()

        # è§£æžGLM APIçš„å“åº”æ ¼å¼
        if 'choices' in result and len(result['choices']) > 0:
            choice = result['choices'][0]
            if 'message' in choice and 'content' in choice['message']:
                analysis_text = choice['message']['content']
                return True, analysis_text.strip(), None
            else:
                return False, None, f"APIå“åº”æ ¼å¼å¼‚å¸¸: {result}"
        else:
            return False, None, f"APIè¿”å›žæ— æœ‰æ•ˆé€‰æ‹©ç»“æžœ: {result}"

    except requests.exceptions.Timeout:
        return False, None, "APIè¯·æ±‚è¶…æ—¶"
    except requests.exceptions.RequestException as e:
        return False, None, f"APIè¯·æ±‚å¤±è´¥: {str(e)}"
    except json.JSONDecodeError as e:
        return False, None, f"APIå“åº”JSONè§£æžå¤±è´¥: {str(e)}"
    except Exception as e:
        return False, None, f"æœªçŸ¥é”™è¯¯: {str(e)}"


def call_deepseek_analysis_api(content, prompt_template):
    """
    è°ƒç”¨DeepSeek APIè¿›è¡Œæ–‡æœ¬åˆ†æžï¼ˆGLMå¤‡é€‰æ–¹æ¡ˆï¼‰
    
    Args:
        content (str): è¦åˆ†æžçš„å†…å®¹
        prompt_template (str): æç¤ºè¯æ¨¡æ¿

    Returns:
        tuple: (success, analysis_result, error_message)
    """
    api_url = "https://api.deepseek.com/v1/chat/completions"
    api_key = os.getenv('DEEPSEEK_API_KEY')
    model_id = os.getenv('DEEPSEEK_MODEL_ID', 'deepseek-chat')

    if not api_key:
        return False, None, "DEEPSEEK_API_KEYçŽ¯å¢ƒå˜é‡æœªè®¾ç½®"

    # ä»ŽçŽ¯å¢ƒå˜é‡èŽ·å–åˆ†æžæç¤ºè¯
    analysis_prompt_template = os.getenv('DEEPSEEK_ANALYSIS_PROMPT', prompt_template)
    # æž„å»ºå®Œæ•´çš„æç¤ºè¯
    full_prompt = analysis_prompt_template.format(content=content)

    headers = {
        'Authorization': f'Bearer {api_key}',
        'Content-Type': 'application/json'
    }

    data = {
        "model": model_id,
        "messages": [
            {
                "role": "user",
                "content": full_prompt
            }
        ],
        "temperature": 0.7,
        "max_tokens": 1024
    }

    try:
        response = requests.post(
            api_url,
            headers=headers,
            json=data,
            timeout=30
        )
        response.raise_for_status()
        
        result = response.json()
        
        if 'choices' in result and len(result['choices']) > 0:
            choice = result['choices'][0]
            if 'message' in choice and 'content' in choice['message']:
                analysis_text = choice['message']['content']
                return True, analysis_text.strip(), None
            else:
                return False, None, f"DeepSeek APIå“åº”æ ¼å¼å¼‚å¸¸: {result}"
        else:
            return False, None, f"DeepSeek APIè¿”å›žæ— æœ‰æ•ˆé€‰æ‹©ç»“æžœ: {result}"

    except requests.exceptions.Timeout:
        return False, None, "DeepSeek APIè¯·æ±‚è¶…æ—¶"
    except requests.exceptions.RequestException as e:
        return False, None, f"DeepSeek APIè¯·æ±‚å¤±è´¥: {str(e)}"
    except json.JSONDecodeError as e:
        return False, None, f"DeepSeek APIå“åº”JSONè§£æžå¤±è´¥: {str(e)}"
    except Exception as e:
        return False, None, f"DeepSeek APIè°ƒç”¨æœªçŸ¥é”™è¯¯: {str(e)}"

def load_extracted_content(query):
    """
    åŠ è½½æ­¥éª¤5çš„æ­£æ–‡æå–ç»“æžœ
    
    Args:
        query (str): æœç´¢å…³é”®è¯
    
    Returns:
        dict: æ­£æ–‡æå–æ•°æ®
    """
    # æŸ¥æ‰¾æœ€æ–°çš„æ­£æ–‡æå–æ–‡ä»¶
    pattern = f"processed_data/05_extracted_article_content/{query}_content_*.json"
    files = glob.glob(pattern)
    
    if not files:
        raise FileNotFoundError(f"æœªæ‰¾åˆ°æŸ¥è¯¢ '{query}' çš„æ­£æ–‡æå–æ–‡ä»¶")
    
    # é€‰æ‹©æœ€æ–°çš„æ–‡ä»¶
    latest_file = max(files, key=os.path.getctime)
    
    with open(latest_file, 'r', encoding='utf-8') as f:
        return json.load(f)

def analyze_news_articles(content_data):
    """
    å¯¹æ‰€æœ‰æ–°é—»æ–‡ç« è¿›è¡ŒAIåˆ†æž
    
    Args:
        content_data (dict): åŒ…å«æ­£æ–‡å†…å®¹çš„æ•°æ®
    
    Returns:
        dict: åŒ…å«åˆ†æžç»“æžœçš„æ•°æ®
    """
    # èŽ·å–åˆ†æžæç¤ºè¯æ¨¡æ¿
    analysis_prompt = os.getenv('GEMINI_ANALYSIS_PROMPT', 
        'è¯·ä½ ä»¥ä¸“ä¸šçš„è§†è§’ï¼Œä¸ºä»¥ä¸‹æ–°é—»æ’°å†™ä¸€æ®µ300åˆ°500å­—çš„åˆ†æžæ‘˜è¦ã€‚å¦‚æžœåŽŸæ–‡æ˜¯å¤–è¯­ï¼Œè¯·ç”¨ä¸­æ–‡è¿›è¡Œåˆ†æžï¼Œå¹¶å¯ä»¥é€‚å½“å¼•ç”¨åŽŸæ–‡å…³é”®ä¿¡æ¯ã€‚æ­£æ–‡å¦‚ä¸‹ï¼š\n\n{content}')
    
    analyzed_items = []
    total_items = len(content_data['news_items'])
    success_count = 0
    failed_count = 0
    
    for idx, news_item in enumerate(content_data['news_items'], 1):
        news_id = news_item['id']
        title = news_item['title']
        content = news_item['content']
        
        print(f"  æ­£åœ¨åˆ†æžç¬¬ {idx}/{total_items} æ¡æ–°é—» (ID: {news_id})...")
        print(f"    æ ‡é¢˜: {title[:50]}{'...' if len(title) > 50 else ''}")
        
        # æ£€æŸ¥å†…å®¹é•¿åº¦
        if len(content.strip()) < 50:
            print(f"    âœ— å†…å®¹å¤ªçŸ­ï¼Œè·³è¿‡åˆ†æž")
            analyzed_item = news_item.copy()
            analyzed_item['analyzed'] = "å†…å®¹å¤ªçŸ­ï¼Œæ— æ³•è¿›è¡Œæœ‰æ•ˆåˆ†æžã€‚"
            analyzed_item['analysis_success'] = False
            analyzed_items.append(analyzed_item)
            failed_count += 1
            continue
        
        # è°ƒç”¨AIè¿›è¡Œåˆ†æžï¼ˆå…ˆå°è¯•GLMï¼Œå¤±è´¥åˆ™å°è¯•DeepSeekï¼‰
        success, analysis_result, error_msg = call_glm_analysis_api(content, analysis_prompt)
        
        if not success:
            print(f"    âš ï¸ GLMåˆ†æžå¤±è´¥: {error_msg}")
            print(f"    ðŸ”„ å°è¯•DeepSeekå¤‡é€‰...")
            
            # å°è¯•DeepSeek API
            success, analysis_result, deepseek_error = call_deepseek_analysis_api(content, analysis_prompt)
            
            if not success:
                print(f"    âŒ DeepSeekä¹Ÿå¤±è´¥: {deepseek_error}")
                error_msg = f"GLM: {error_msg}, DeepSeek: {deepseek_error}"
        
        if success and analysis_result:
            analyzed_item = news_item.copy()
            analyzed_item['analyzed'] = analysis_result
            analyzed_item['analysis_success'] = True
            analyzed_items.append(analyzed_item)
            success_count += 1
            
            print(f"    âœ“ åˆ†æžæˆåŠŸ ({len(analysis_result)} å­—ç¬¦)")
        else:
            analyzed_item = news_item.copy()
            analyzed_item['analyzed'] = f"æ‰€æœ‰AIéƒ½åˆ†æžå¤±è´¥: {error_msg}"
            analyzed_item['analysis_success'] = False
            analyzed_items.append(analyzed_item)
            failed_count += 1
            
            print(f"    âœ— åˆ†æžå¤±è´¥: {error_msg}")
        
        # æ·»åŠ å»¶è¿Ÿï¼Œé¿å…APIé™æµ
        if idx < total_items:  # æœ€åŽä¸€ä¸ªä¸éœ€è¦å»¶è¿Ÿ
            time.sleep(2)
    
    # æ›´æ–°æ•°æ®ç»“æž„
    analyzed_data = content_data.copy()
    analyzed_data['news_items'] = analyzed_items
    analyzed_data['processed_time'] = datetime.now().isoformat()
    analyzed_data['ai_analysis'] = {
        'total_items': total_items,
        'success_count': success_count,
        'failed_count': failed_count,
        'analysis_model': os.getenv('GEMINI_MODEL_ID', 'gemini-2.0-flash-exp')
    }
    
    return analyzed_data

def save_analyzed_data(query, analyzed_data):
    """
    ä¿å­˜AIåˆ†æžç»“æžœ
    
    Args:
        query (str): æœç´¢å…³é”®è¯
        analyzed_data (dict): åŒ…å«åˆ†æžç»“æžœçš„æ•°æ®
    
    Returns:
        str: ä¿å­˜çš„æ–‡ä»¶è·¯å¾„
    """
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = 'processed_data/06_ai_processed_data'
    os.makedirs(output_dir, exist_ok=True)
    
    # ç”Ÿæˆæ–‡ä»¶å
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    filename = f"{query}_analyzed_{timestamp}.json"
    filepath = os.path.join(output_dir, filename)
    
    # ä¿å­˜æ–‡ä»¶
    with open(filepath, 'w', encoding='utf-8') as f:
        json.dump(analyzed_data, f, ensure_ascii=False, indent=2)
    
    return filepath

def step6_ai_analysis(query):
    """
    æ­¥éª¤6ä¸»å‡½æ•°ï¼šAIæ·±åº¦åˆ†æž
    
    Args:
        query (str): æœç´¢å…³é”®è¯
    
    Returns:
        str: ä¿å­˜çš„æ–‡ä»¶è·¯å¾„
    """
    print(f"[Step 6/7] Performing AI deep analysis...")
    
    # åŠ è½½æ­£æ–‡æå–ç»“æžœ
    print("  æ­£åœ¨åŠ è½½æ­£æ–‡æå–ç»“æžœ...")
    content_data = load_extracted_content(query)
    
    total_items = len(content_data['news_items'])
    print(f"  éœ€è¦åˆ†æž {total_items} æ¡æ–°é—»")
    
    # è¿›è¡ŒAIåˆ†æž
    print("  å¼€å§‹AIæ·±åº¦åˆ†æž...")
    analyzed_data = analyze_news_articles(content_data)
    
    # ä¿å­˜ç»“æžœ
    filepath = save_analyzed_data(query, analyzed_data)
    
    analysis_stats = analyzed_data['ai_analysis']
    print(f"  æ­¥éª¤6å®Œæˆï¼")
    print(f"  æˆåŠŸåˆ†æž: {analysis_stats['success_count']}/{analysis_stats['total_items']}")
    print(f"  åˆ†æžå¤±è´¥: {analysis_stats['failed_count']}")
    print(f"  ç»“æžœå·²ä¿å­˜åˆ°: {filepath}")
    
    return filepath

if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    test_query = "è‹±ä¼Ÿè¾¾"
    try:
        result_file = step6_ai_analysis(test_query)
        print(f"æµ‹è¯•å®Œæˆï¼Œç»“æžœæ–‡ä»¶: {result_file}")
    except Exception as e:
        print(f"æµ‹è¯•å¤±è´¥: {e}")
