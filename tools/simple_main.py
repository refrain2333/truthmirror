#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ™ºèƒ½æ–°é—»åˆ†æç³»ç»Ÿ - ç®€åŒ–ç‰ˆä¸»ç¨‹åº
ä»…ä½¿ç”¨Pythonæ ‡å‡†åº“çš„åŸºæœ¬ç‰ˆæœ¬
"""

import sys
import os
import json
import urllib.request
import urllib.parse
import urllib.error
import time
from datetime import datetime

def print_banner():
    """æ‰“å°ç¨‹åºæ¨ªå¹…"""
    banner = """
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    æ™ºèƒ½æ–°é—»åˆ†æç³»ç»Ÿ                          â•‘
â•‘                 Intelligent News Analysis System             â•‘
â•‘                                                              â•‘
â•‘  è‡ªåŠ¨åŒ–ä¸ƒæ­¥æµç¨‹ï¼šæ–°é—»è·å– â†’ ç­›é€‰ â†’ åˆ†æ â†’ æ±‡æ€»æŠ¥å‘Š          â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""
    print(banner)

def fetch_news_simple(query, page=1):
    """
    ä½¿ç”¨æ ‡å‡†åº“è·å–æ–°é—»æ•°æ®
    """
    api_url = "http://115.120.215.107:8888/search"
    
    params = {
        'q': query,
        'categories': 'news',
        'format': 'json',
        'pageno': page
    }
    
    # æ„å»ºURL
    url = f"{api_url}?{urllib.parse.urlencode(params)}"
    
    try:
        print(f"  æ­£åœ¨è·å–ç¬¬ {page} é¡µæ•°æ®...")
        
        # è®¾ç½®è¯·æ±‚å¤´
        req = urllib.request.Request(url)
        req.add_header('User-Agent', 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36')
        
        # å‘é€è¯·æ±‚
        with urllib.request.urlopen(req, timeout=30) as response:
            data = response.read().decode('utf-8')
            return json.loads(data)
            
    except urllib.error.URLError as e:
        print(f"  è·å–ç¬¬ {page} é¡µæ•°æ®å¤±è´¥: {e}")
        return None
    except json.JSONDecodeError as e:
        print(f"  è§£æç¬¬ {page} é¡µæ•°æ®å¤±è´¥: {e}")
        return None
    except Exception as e:
        print(f"  è·å–ç¬¬ {page} é¡µæ•°æ®æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return None

def check_url_simple(url):
    """
    ç®€å•æ£€æŸ¥URLå¯è®¿é—®æ€§
    """
    try:
        req = urllib.request.Request(url, method='HEAD')
        req.add_header('User-Agent', 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36')
        
        with urllib.request.urlopen(req, timeout=10) as response:
            return 200 <= response.status < 400
    except:
        return False

def simple_analysis_pipeline(query):
    """
    ç®€åŒ–çš„åˆ†ææµç¨‹
    """
    print(f"\nğŸ” å¼€å§‹åˆ†æä¸»é¢˜: '{query}'")
    print(f"ğŸ• å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    # æ­¥éª¤1: è·å–æ–°é—»æ•°æ®
    print("\n" + "="*60)
    print("[Step 1/3] è·å–æ–°é—»æ•°æ®...")
    
    all_news = []
    for page in range(1, 4):  # è·å–3é¡µæ•°æ®
        result = fetch_news_simple(query, page)
        if result and 'results' in result:
            all_news.extend(result['results'])
        time.sleep(1)  # é¿å…è¯·æ±‚è¿‡å¿«
    
    if not all_news:
        print("âŒ æ— æ³•è·å–æ–°é—»æ•°æ®")
        return
    
    print(f"âœ… æˆåŠŸè·å– {len(all_news)} æ¡æ–°é—»")
    
    # æ­¥éª¤2: ç®€å•ç­›é€‰
    print("\n" + "="*60)
    print("[Step 2/3] ç­›é€‰æœ‰æ•ˆæ–°é—»...")
    
    valid_news = []
    for idx, news in enumerate(all_news[:20], 1):  # åªå¤„ç†å‰20æ¡
        if news.get('title') and news.get('url'):
            print(f"  æ£€æŸ¥ç¬¬ {idx} æ¡æ–°é—»...")
            if check_url_simple(news['url']):
                valid_news.append({
                    'id': len(valid_news) + 1,
                    'title': news['title'],
                    'url': news['url'],
                    'content': news.get('content', ''),
                    'engine': news.get('engine', '')
                })
                print(f"    âœ… æœ‰æ•ˆ")
            else:
                print(f"    âŒ æ— æ³•è®¿é—®")
        
        if len(valid_news) >= 10:  # æœ€å¤šä¿ç•™10æ¡
            break
    
    print(f"âœ… ç­›é€‰å‡º {len(valid_news)} æ¡æœ‰æ•ˆæ–°é—»")
    
    # æ­¥éª¤3: ä¿å­˜ç»“æœ
    print("\n" + "="*60)
    print("[Step 3/3] ä¿å­˜åˆ†æç»“æœ...")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs('processed_data/simple_results', exist_ok=True)
    
    # ç”ŸæˆæŠ¥å‘Š
    report = {
        'query': query,
        'generated_time': datetime.now().isoformat(),
        'total_news_found': len(all_news),
        'valid_news_count': len(valid_news),
        'news_items': valid_news,
        'summary': f"å…³äº'{query}'çš„æ–°é—»åˆ†æï¼šå…±æ‰¾åˆ°{len(all_news)}æ¡ç›¸å…³æ–°é—»ï¼Œå…¶ä¸­{len(valid_news)}æ¡å¯ä»¥æ­£å¸¸è®¿é—®ã€‚"
    }
    
    # ä¿å­˜æ–‡ä»¶
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    filename = f"processed_data/simple_results/{query}_simple_{timestamp}.json"
    
    with open(filename, 'w', encoding='utf-8') as f:
        json.dump(report, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… ç»“æœå·²ä¿å­˜åˆ°: {filename}")
    
    # æ˜¾ç¤ºæ‘˜è¦
    print("\n" + "="*60)
    print("ğŸ“Š åˆ†æå®Œæˆï¼")
    print("="*60)
    print(f"ğŸ“ ä¸»é¢˜: {query}")
    print(f"ğŸ“… æ—¶é—´: {report['generated_time']}")
    print(f"ğŸ“ˆ ç»Ÿè®¡:")
    print(f"   â€¢ æ€»æ–°é—»æ•°: {report['total_news_found']}")
    print(f"   â€¢ æœ‰æ•ˆæ–°é—»: {report['valid_news_count']}")
    print(f"\nğŸ“„ æ–°é—»åˆ—è¡¨:")
    for news in valid_news:
        print(f"   {news['id']}. {news['title'][:60]}{'...' if len(news['title']) > 60 else ''}")
    
    print(f"\nğŸ’¾ å®Œæ•´æŠ¥å‘Š: {filename}")

def main():
    """ä¸»å‡½æ•°"""
    print_banner()
    
    # è·å–ç”¨æˆ·è¾“å…¥
    if len(sys.argv) > 1:
        query = sys.argv[1]
    else:
        query = input("\nè¯·è¾“å…¥æœç´¢å…³é”®è¯: ").strip()
    
    if not query:
        print("âŒ æœç´¢å…³é”®è¯ä¸èƒ½ä¸ºç©º")
        sys.exit(1)
    
    try:
        # è¿è¡Œç®€åŒ–çš„åˆ†ææµç¨‹
        simple_analysis_pipeline(query)
        
    except KeyboardInterrupt:
        print("\n\nâš ï¸  ç”¨æˆ·ä¸­æ–­äº†ç¨‹åºæ‰§è¡Œ")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

if __name__ == "__main__":
    main()
