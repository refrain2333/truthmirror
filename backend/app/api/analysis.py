"""
æ™ºèƒ½åˆ†æAPIç«¯ç‚¹
"""

from fastapi import APIRouter, HTTPException, BackgroundTasks
from ..services.simple_db_service import db_service
from ..config import settings
from pydantic import BaseModel
from typing import Dict, Any
from datetime import datetime
from pathlib import Path
import json

from ..services.analysis_service import run_news_analysis, get_analysis_result

router = APIRouter()


class AnalysisRequest(BaseModel):
    """åˆ†æè¯·æ±‚æ¨¡å‹"""
    event_title: str
    event_description: str
    event_id: int = None  # äº‹ä»¶IDï¼Œç”¨äºçŠ¶æ€ç®¡ç†


@router.post("/analyze")
async def analyze_event(request: AnalysisRequest, background_tasks: BackgroundTasks):
    """
    åˆ†æäº‹ä»¶ - çœŸæ­£çš„åå°AIåˆ†æ
    
    Args:
        request: åˆ†æè¯·æ±‚
        background_tasks: FastAPIåå°ä»»åŠ¡
        
    Returns:
        ç«‹å³è¿”å›å¯åŠ¨çŠ¶æ€ï¼ŒçœŸæ­£çš„AIåˆ†æåœ¨åå°è¿è¡Œ
    """
    try:
        event_id = request.event_id or 999
        # åç«¯å‰ç½®æ ¡éªŒï¼šå…³æ³¨äººæ•°â‰¥10 æˆ–å·²é€šè¿‡ç®¡ç†å‘˜å®¡æ ¸ï¼Œå¦åˆ™æ‹’ç»å¯åŠ¨
        try:
            event = db_service.get_event_detail(event_id)
            interest_count = int(event.get('interest_count') or 0)
            status_val = event.get('status')
            min_interest = int(getattr(settings, 'interest_threshold', 10))
            if interest_count < min_interest and status_val == 'pending':
                return {
                    "success": False,
                    "event_id": event_id,
                    "error": f"å…³æ³¨äººæ•°ä¸è¶³{min_interest}ä¸”æœªå®¡æ ¸ï¼Œæš‚ä¸å¯åŠ¨AIåˆ†æ",
                    "ai_analysis": {"reliability": "insufficient", "summary": "è¯·ç­‰å¾…æ›´å¤šäººå…³æ³¨æˆ–ç®¡ç†å‘˜å®¡æ ¸é€šè¿‡åå†è¯•"},
                    "next_step": "WAITING_FOR_INTEREST_OR_APPROVAL",
                    "timestamp": datetime.now().isoformat()
                }
        except Exception:
            pass
        query = f"{request.event_title} {request.event_description}"
        
        print(f"ğŸš€ [äº‹ä»¶{event_id}] å¯åŠ¨çœŸå®AIåˆ†æ: {query[:50]}...")
        
        # é¢„å†™å…¥ä¸€ä¸ªâ€œå·²å¯åŠ¨â€çš„çŠ¶æ€ï¼Œé¿å…å‰ç«¯åœ¨ä»»åŠ¡æ’é˜Ÿæ—¶çœ‹åˆ° idle
        try:
            status_file = Path(__file__).resolve().parents[2] / 'modules' / 'TruthNews' / 'news_analysis' / f'status_event_{event_id}.json'
            status_file.parent.mkdir(parents=True, exist_ok=True)
            with open(status_file, 'w', encoding='utf-8') as sf:
                json.dump({
                    "status": "started",
                    "step": "step1_search",
                    "event_id": event_id,
                    "raw_count": 0,
                    "started_at": datetime.now().isoformat(),
                    "updated_at": datetime.now().isoformat()
                }, sf, ensure_ascii=False, indent=2)
        except Exception:
            pass

        # å®šä¹‰åå°åˆ†æä»»åŠ¡
        def background_ai_analysis():
            print(f"ğŸ¤– [äº‹ä»¶{event_id}] å¼€å§‹åå°AIåˆ†æ...")
            try:
                result = run_news_analysis(
                    event_title=request.event_title,
                    event_description=request.event_description,
                    event_id=event_id
                )
                print(f"âœ… [äº‹ä»¶{event_id}] AIåˆ†æå®Œæˆ: {result.get('success', False)}")
                if result.get('success'):
                    print(f"ğŸ“Š [äº‹ä»¶{event_id}] AIè¯„çº§: {result.get('ai_analysis', {}).get('reliability', 'unknown')}")
                    print(f"ğŸ“ [äº‹ä»¶{event_id}] æ‘˜è¦é•¿åº¦: {len(result.get('ai_analysis', {}).get('summary', ''))}")
                else:
                    print(f"âŒ [äº‹ä»¶{event_id}] åˆ†æå¤±è´¥: {result.get('error', 'unknown')}")
            except Exception as e:
                print(f"ğŸ’¥ [äº‹ä»¶{event_id}] åå°åˆ†æå¼‚å¸¸: {str(e)}")
        
        # æ·»åŠ åˆ°åå°ä»»åŠ¡é˜Ÿåˆ—
        background_tasks.add_task(background_ai_analysis)
        
        # ç«‹å³è¿”å›å¯åŠ¨çŠ¶æ€
        return {
            "success": True,
            "event_id": event_id,
            "query": query,
            "status": "analysis_started", 
            "message": "ğŸš€ çœŸå®AIåˆ†æå·²åœ¨åå°å¯åŠ¨ï¼",
            "ai_analysis": {
                "reliability": "processing",
                "summary": f"æ­£åœ¨å¯¹'{request.event_title}'è¿›è¡Œ7æ­¥æ™ºèƒ½åˆ†æ...\n\nğŸ“Š åˆ†æè¿‡ç¨‹ï¼š\n1. ğŸ” æœç´¢ç›¸å…³æ–°é—»\n2. ğŸŒ æ£€æµ‹é“¾æ¥å¯ç”¨æ€§\n3. ğŸ¤– AIç­›é€‰ç›¸å…³å†…å®¹\n4. ğŸ“„ æŠ“å–ç½‘é¡µå†…å®¹\n5. ğŸ“ æå–æ­£æ–‡ä¿¡æ¯\n6. ğŸ§  GLM/DeepSeekæ·±åº¦åˆ†æ\n7. ğŸ“‹ ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š\n\nâ³ è¯·ç­‰å¾…1-2åˆ†é’Ÿï¼Œå¯åœ¨ç»ˆç«¯æŸ¥çœ‹å®æ—¶è¿›åº¦ã€‚",
                "analysis_statistics": {
                    "status": "background_processing",
                    "steps_total": 7,
                    "models_used": ["GLM-4.5-flash", "DeepSeek(å¤‡é€‰)"],
                    "started_at": datetime.now().isoformat()
                },
                "workflow_summary": {
                    "status": "started",
                    "background_task": True,
                    "check_terminal": "æŸ¥çœ‹ç»ˆç«¯è¾“å‡ºäº†è§£åˆ†æè¿›åº¦"
                }
            },
            "timestamp": datetime.now().isoformat(),
            "next_step": "BACKGROUND_PROCESSING",
            "note": "ğŸ”¥ æ³¨æ„ï¼šè¿™æ¬¡æ˜¯çœŸæ­£çš„AIåˆ†æï¼è¯·æŸ¥çœ‹ç»ˆç«¯è¾“å‡ºäº†è§£å®æ—¶è¿›åº¦ã€‚"
        }
        
    except Exception as e:
        print(f"âŒ å¯åŠ¨AIåˆ†æå¤±è´¥: {str(e)}")
        return {
            "success": False,
            "event_id": request.event_id or 999,
            "query": f"{request.event_title} {request.event_description}",
            "error": f"æ— æ³•å¯åŠ¨AIåˆ†æ: {str(e)}",
            "ai_analysis": {
                "reliability": "insufficient", 
                "summary": "âŒ ç³»ç»Ÿæ— æ³•å¯åŠ¨AIåˆ†æï¼Œè¯·æ£€æŸ¥é…ç½®æˆ–ç¨åé‡è¯•ã€‚",
                "analysis_statistics": {"error": "startup_failed"},
                "workflow_summary": {"status": "failed", "error": str(e)[:100]}
            },
            "timestamp": datetime.now().isoformat(),
            "next_step": "RETRY"
        }


@router.post("/test")
async def test_analysis():
    """
    æµ‹è¯•åˆ†æåŠŸèƒ½ - å¿«é€Ÿå“åº”
    """
    return {
        "message": "âœ… åˆ†æAPIæµ‹è¯•æˆåŠŸ",
        "status": "ok",
        "timestamp": datetime.now().isoformat(),
        "note": "APIç«¯ç‚¹æ­£å¸¸å·¥ä½œï¼Œå¯ä»¥æ¥æ”¶åˆ†æè¯·æ±‚"
    }


@router.post("/run-full-analysis")
async def run_full_analysis(request: AnalysisRequest, background_tasks: BackgroundTasks):
    """
    æ‰§è¡Œå®Œæ•´çš„AIåˆ†æï¼ˆåå°ä»»åŠ¡ï¼‰
    """
    def background_analysis():
        try:
            print(f"ğŸš€ å¼€å§‹åå°AIåˆ†æ...")
            result = run_news_analysis(
                event_title=request.event_title,
                event_description=request.event_description,
                event_id=request.event_id
            )
            print(f"âœ… åå°AIåˆ†æå®Œæˆ: {result.get('success', False)}")
        except Exception as e:
            print(f"âŒ åå°AIåˆ†æå¤±è´¥: {str(e)}")
    
    # æ·»åŠ åå°ä»»åŠ¡
    background_tasks.add_task(background_analysis)
    
    return {
        "message": "åå°åˆ†æä»»åŠ¡å·²å¯åŠ¨",
        "event_id": request.event_id,
        "status": "background_processing"
    }


@router.get("/result/{event_id}")
async def get_final_result(event_id: int):
    """è¿”å›æœ€ç»ˆç»“æœï¼šè‹¥çŠ¶æ€æ–‡ä»¶åŒ…å« result_file æˆ–å†…è”ç»“æœï¼Œä¼˜å…ˆè¯»å–å¹¶è¿”å›"""
    try:
        from pathlib import Path
        import json
        status_file = Path(__file__).resolve().parents[2] / 'modules' / 'TruthNews' / 'news_analysis' / f'status_event_{event_id}.json'
        if status_file.exists():
            with open(status_file, 'r', encoding='utf-8') as f:
                status = json.load(f)
            if status.get('result_inline'):
                return {"success": True, "event_id": event_id, "detailed_result": status['result_inline']}
            if status.get('result_file') and Path(status['result_file']).exists():
                with open(status['result_file'], 'r', encoding='utf-8') as rf:
                    detailed = json.load(rf)
                return {"success": True, "event_id": event_id, "detailed_result": detailed}
        return {"success": False, "event_id": event_id, "error": "result_not_ready"}
    except Exception as e:
        return {"success": False, "event_id": event_id, "error": str(e)}


@router.get("/status/{event_id}")
async def get_analysis_status(event_id: int):
    """è¿”å›åç«¯å†™å…¥çš„çœŸå®è¿›åº¦çŠ¶æ€æ–‡ä»¶"""
    try:
        status_file = Path(__file__).resolve().parents[2] / 'modules' / 'TruthNews' / 'news_analysis' / f'status_event_{event_id}.json'
        if status_file.exists():
            with open(status_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            return {"success": True, **data}
        return {"success": True, "status": "idle", "event_id": event_id}
    except Exception as e:
        return {"success": False, "status": "error", "error": str(e), "event_id": event_id}


@router.get("/status")
async def get_all_analysis_status():
    """èšåˆè¿”å›æ‰€æœ‰äº‹ä»¶çš„åˆ†æçŠ¶æ€ï¼ˆä¾¿äºé¦–é¡µç»Ÿä¸€å±•ç¤ºï¼‰ã€‚"""
    try:
        base = Path(__file__).resolve().parents[2] / 'modules' / 'TruthNews' / 'news_analysis'
        results = []
        if base.exists():
            for f in base.glob('status_event_*.json'):
                try:
                    with open(f, 'r', encoding='utf-8') as rf:
                        data = json.load(rf)
                        # ä»æ–‡ä»¶åæå–äº‹ä»¶ID
                        try:
                            eid = int(f.stem.replace('status_event_', ''))
                        except Exception:
                            eid = data.get('event_id')
                        data['event_id'] = data.get('event_id') or eid
                        results.append({
                            'event_id': data.get('event_id'),
                            'status': data.get('status'),
                            'step': data.get('step'),
                            'raw_count': data.get('raw_count'),
                            'accessible': data.get('accessible'),
                            'relevant': data.get('relevant'),
                            'updated_at': data.get('updated_at') or data.get('finished_at')
                        })
                except Exception:
                    continue
        return {"success": True, "items": results}
    except Exception as e:
        return {"success": False, "error": str(e)}